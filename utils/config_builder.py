"""
Build MMDetection config files from user settings
"""
import os
import sys
from pathlib import Path

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent.parent))
from configs.model_configs import get_model_config


def build_mmdet_config(
    model_size,
    data_root,
    class_names,
    num_classes,
    img_size,
    epochs,
    batch_size=None,
    lr=0.01,
    momentum=0.937,
    weight_decay=0.0005,
    warmup_epochs=3,
    work_dir=None,
    mosaic_prob=1.0,
    mixup_prob=0.1,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=10.0,
    translate=0.1,
    scale=0.5,
    shear=2.0,
    flipud=0.0,
    fliplr=0.5
):
    """
    Build MMDetection config file content

    Args:
        model_size: 'nano', 'small', 'medium', or 'large'
        data_root: Path to COCO format dataset
        class_names: List of class names
        num_classes: Number of classes
        img_size: Image size (width, height)
        epochs: Number of training epochs
        batch_size: Batch size (if None, uses default from model config)
        lr: Learning rate
        momentum: SGD momentum
        weight_decay: Weight decay
        warmup_epochs: Number of warmup epochs
        work_dir: Working directory for outputs

    Returns:
        str: Config file content
    """

    model_config = get_model_config(model_size)

    if batch_size is None:
        batch_size = model_config['batch_size']

    if work_dir is None:
        work_dir = f'./work_dirs/solov2_{model_size}'

    # Convert class names to tuple format
    classes_str = str(tuple(class_names))

    config_content = f'''# SOLOv2 {model_size.upper()} Configuration
# Auto-generated by SOLOv2 Trainer

_base_ = [
    '/home/farshid/anaconda3/envs/rgbt/lib/python3.11/site-packages/mmdet/.mim/configs/_base_/schedules/schedule_1x.py',
    '/home/farshid/anaconda3/envs/rgbt/lib/python3.11/site-packages/mmdet/.mim/configs/_base_/default_runtime.py'
]

# Dataset settings
dataset_type = 'CocoDataset'
data_root = '{data_root}'
classes = {classes_str}
num_classes = {num_classes}

# Model settings - {model_size.upper()} variant
model = dict(
    type='SOLOv2',
    data_preprocessor=dict(
        type='DetDataPreprocessor',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        bgr_to_rgb=True,
        pad_mask=True,
        pad_size_divisor=32),
    backbone=dict(
        type='{model_config['backbone']['type']}',
        depth={model_config['backbone']['depth']},
        num_stages={model_config['backbone']['num_stages']},
        out_indices={model_config['backbone']['out_indices']},
        frozen_stages={model_config['backbone']['frozen_stages']},
        init_cfg=dict(type='Pretrained', checkpoint='{model_config['backbone']['init_cfg']['checkpoint']}'),
        style='{model_config['backbone']['style']}'),
    neck=dict(
        type='{model_config['neck']['type']}',
        in_channels={model_config['neck']['in_channels']},
        out_channels={model_config['neck']['out_channels']},
        start_level={model_config['neck']['start_level']},
        num_outs={model_config['neck']['num_outs']}),
    mask_head=dict(
        type='SOLOV2Head',
        num_classes=num_classes,
        in_channels={model_config['mask_head']['in_channels']},
        feat_channels={model_config['mask_head']['feat_channels']},
        stacked_convs={model_config['mask_head']['stacked_convs']},
        strides=[8, 8, 16, 32, 32],
        scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        pos_scale=0.2,
        num_grids=[40, 36, 24, 16, 12],
        cls_down_index=0,
        mask_feature_head=dict(
            feat_channels={model_config['mask_head']['mask_feature_head']['feat_channels']},
            start_level={model_config['mask_head']['mask_feature_head']['start_level']},
            end_level={model_config['mask_head']['mask_feature_head']['end_level']},
            out_channels={model_config['mask_head']['mask_feature_head']['out_channels']},
            mask_stride={model_config['mask_head']['mask_feature_head']['mask_stride']},
            norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
        loss_mask=dict(type='DiceLoss', use_sigmoid=True, loss_weight=3.0),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    test_cfg=dict(
        nms_pre=500,
        score_thr=0.1,
        mask_thr=0.5,
        filter_thr=0.05,
        kernel='gaussian',
        sigma=2.0,
        max_per_img=100))

# Data pipeline
img_scale = ({img_size[0]}, {img_size[1]})
backend_args = None

train_pipeline = [
    dict(type='LoadImageFromFile', backend_args=backend_args),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    # Mosaic augmentation (4-image mixing)
    dict(
        type='Mosaic',
        img_scale=img_scale,
        pad_val=114.0,
        prob={mosaic_prob}),
    # Random affine transformation
    dict(
        type='RandomAffine',
        max_rotate_degree={degrees},
        max_translate_ratio={translate},
        scaling_ratio_range=({1 - scale}, {1 + scale}),
        max_shear_degree={shear},
        border=(-img_scale[0] // 2, -img_scale[1] // 2)),
    # MixUp augmentation
    dict(type='MixUp', img_scale=img_scale, ratio_range=(0.8, 1.6), pad_val=114.0, prob={mixup_prob}),
    # Color augmentation (HSV, brightness, contrast)
    dict(
        type='PhotoMetricDistortion',
        brightness_delta=int(255 * {hsv_v}),
        contrast_range=(1 - {hsv_v}, 1 + {hsv_v}),
        saturation_range=(1 - {hsv_s}, 1 + {hsv_s}),
        hue_delta=int(180 * {hsv_h})),
    # Resize with scale jitter
    dict(
        type='Resize',
        scale=img_scale,
        keep_ratio=True),
    # Random crop
    dict(
        type='RandomCrop',
        crop_size=(int(img_scale[0] * 0.9), int(img_scale[1] * 0.9)),
        crop_type='absolute',
        allow_negative_crop=True),
    # Resize back to target size
    dict(type='Resize', scale=img_scale, keep_ratio=False),
    # Random flip (horizontal)
    dict(type='RandomFlip', prob={fliplr}, direction='horizontal'),
    # Random flip (vertical)
    dict(type='RandomFlip', prob={flipud}, direction='vertical'),
    dict(type='PackDetInputs')
]

test_pipeline = [
    dict(type='LoadImageFromFile', backend_args=backend_args),
    dict(type='Resize', scale=img_scale, keep_ratio=True),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(
        type='PackDetInputs',
        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor'))
]

# Dataloaders
train_dataloader = dict(
    batch_size={batch_size},
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        data_root=data_root,
        ann_file='annotations/instances_train.json',
        data_prefix=dict(img='train/'),
        filter_cfg=dict(filter_empty_gt=False, min_size=32),
        pipeline=train_pipeline,
        backend_args=backend_args,
        metainfo=dict(classes=classes)))

val_dataloader = dict(
    batch_size={batch_size},
    num_workers=4,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        data_root=data_root,
        ann_file='annotations/instances_val.json',
        data_prefix=dict(img='val/'),
        test_mode=True,
        pipeline=test_pipeline,
        backend_args=backend_args,
        metainfo=dict(classes=classes)))

test_dataloader = val_dataloader

# Evaluators
val_evaluator = dict(
    type='CocoMetric',
    ann_file=data_root + 'annotations/instances_val.json',
    metric=['segm'],
    backend_args=backend_args)
test_evaluator = val_evaluator

# Training settings
max_epochs = {epochs}
train_cfg = dict(max_epochs=max_epochs, val_interval=10)

# Optimizer
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(type='SGD', lr={lr}, momentum={momentum}, weight_decay={weight_decay}),
    clip_grad=dict(max_norm=35, norm_type=2))

# Learning rate scheduler with warmup
param_scheduler = [
    dict(
        type='LinearLR',
        start_factor=0.001,
        by_epoch=True,
        begin=0,
        end={warmup_epochs}),
    dict(
        type='CosineAnnealingLR',
        T_max=max_epochs - {warmup_epochs},
        eta_min={lr * 0.01},
        begin={warmup_epochs},
        end=max_epochs,
        by_epoch=True)
]

# Default hooks
default_hooks = dict(
    checkpoint=dict(type='CheckpointHook', interval=10, max_keep_ckpts=3),
    logger=dict(type='LoggerHook', interval=10))

# Runtime settings
work_dir = '{work_dir}'
'''

    return config_content
